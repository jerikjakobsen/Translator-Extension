{"version":3,"file":"content-bundle.js","mappings":";;;;;;AACA;AAAA;AAAA;AADA;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AAAA;AAAA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AACA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["webpack://translator-extension/./content.js"],"sourcesContent":["let audioContext = new AudioContext();\nlet processorURL = chrome.runtime.getURL(\"dist/IntermediateAudioProcessor.js\");\nasync function createMyAudioProcessor() {\n    try {\n        //audioContext = new AudioContext();\n        //await audioContext.resume();\n        console.log(processorURL)\n        await audioContext.audioWorklet.addModule(processorURL, {\n            credentials: 'omit',\n          });\n    } catch (e) {\n        console.log(e);\n        return null;\n    }\n\n  return new AudioWorkletNode(audioContext, \"intermediate-audio-processor\");\n}\n\nfunction waitForAudio(selector) {\n    return new Promise(resolve => {\n        if (document.querySelector(selector)) {\n            return resolve(document.querySelector(selector));\n        }\n\n        const observer = new MutationObserver(mutations => {\n            if (document.querySelector(selector)) {\n                resolve(document.querySelector(selector));\n                observer.disconnect();\n            }\n        });\n\n        observer.observe(document.body, {\n            childList: true,\n            subtree: true\n        });\n    });\n}\n\ncreateMyAudioProcessor().then(x => {\n    console.log(\"audio processor \" + x)\n    intercepterWorkletNode = x\n    var vid = document.getElementsByTagName('video')[0]\n    console.log(\"In the Content.js Code\")\n    if (vid != null) {\n        var stream = vid.captureStream()\n        let alreadyAdded = false\n        stream.addEventListener(\"addtrack\", (event) => {\n            if (!alreadyAdded && event.track.kind === 'audio') {\n                alreadyAdded = true\n                console.log(\"Creating and connecting node\")\n                let audioSourceNode = audioContext.createMediaStreamSource(stream)\n                audioSourceNode.connect(intercepterWorkletNode)\n            }\n        });\n    }\n    \n})\n\n\n/*\n\n{\n    \"manifest_version\": 3,\n    \"name\": \"Translator\",\n    \"description\": \"Translating videos on the fly.\",\n    \"version\": \"1.0\",\n    \"content_scripts\": [\n        {\n            \"matches\": [\n                \"<all_urls>\"\n            ],\n            \"js\": [\"dist/bundle.js\"]\n        }\n    ],\n    \"web_accessible_resources\": [\n        {\n            \"resources\": [\"modules/IntermediateAudioProcessor.js\"],\n            \"matches\": [\"<all_urls>\"]\n        }\n    ]\n}\n\n*/"],"names":[],"sourceRoot":""}